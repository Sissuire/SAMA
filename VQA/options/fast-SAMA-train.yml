
name: SAMA-VQA-sama
num_epochs: 30
l_num_epochs: 0
warmup_epochs: 2.5
ema: true
save_model: true
train_batch_size: 12
train_num_workers: 6
test_batch_size: 1
test_num_workers: 6

stype: sama  # [sama, sama-c, sama-mix, sama-swm, sama-spm, fragments==others]

data:
    train:
        type: FusionDataset
        args:
            phase: train
            anno_file: ./examplar_data_labels/LSVQ/labels_mytrain.txt
            data_prefix: PATH_TO_DATA/LSVQ
            sample_types:
                fragments:
                    fragments_h: 7
                    fragments_w: 7
                    fsize_h: 32
                    fsize_w: 32
                    aligned: 32
                    clip_len: 32
                    frame_interval: 2
                    num_clips: 1
    val-livevqc:
        type: FusionDataset
        args:
            phase: test
            anno_file: ./examplar_data_labels/LIVE_VQC/mylabels.txt
            data_prefix: PATH_TO_DATA/LIVE-VQC
            sample_types:
                fragments:
                    fragments_h: 7
                    fragments_w: 7
                    fsize_h: 32
                    fsize_w: 32
                    aligned: 32
                    clip_len: 32
                    frame_interval: 2
                    num_clips: 4
    val-kv1k:
        type: FusionDataset
        args:
            phase: test
            anno_file: ./examplar_data_labels/KoNViD/mylabels.txt
            data_prefix: PATH_TO_DATA/KoNViD
            sample_types:
                fragments:
                    fragments_h: 7
                    fragments_w: 7
                    fsize_h: 32
                    fsize_w: 32
                    aligned: 32
                    clip_len: 32
                    frame_interval: 2
                    num_clips: 4
    val-ltest:
        type: FusionDataset
        args:
            phase: test
            anno_file: ./examplar_data_labels/LSVQ/labels_mytest.txt
            data_prefix: PATH_TO_DATA/LSVQ
            sample_types:
                fragments:
                    fragments_h: 7
                    fragments_w: 7
                    fsize_h: 32
                    fsize_w: 32
                    aligned: 32
                    clip_len: 32
                    frame_interval: 2
                    num_clips: 4 
    val-l1080p:
        type: FusionDataset
        args:
            phase: test
            anno_file: ./examplar_data_labels/LSVQ/labels_mytest_1080p.txt
            data_prefix: PATH_TO_DATA/LSVQ
            sample_types:
                fragments:
                    fragments_h: 7
                    fragments_w: 7
                    fsize_h: 32
                    fsize_w: 32
                    aligned: 32
                    clip_len: 32
                    frame_interval: 2
                    num_clips: 4 
model:
    type: DiViDeAddEvaluator
    args:
        backbone:
            fragments:
                checkpoint: false
                pretrained: 
        backbone_size: swin_tiny_grpb
        backbone_preserve_keys: fragments
        divide_head: false
        vqa_head:
            in_channels: 768
            hidden_channels: 64
            
optimizer:
    lr: !!float 1e-3
    backbone_lr_mult: !!float 1e-1
    wd: 0.05
        
load_path: PATH_TO_MODEL/swin_tiny_patch244_window877_kinetics400_1k.pth
